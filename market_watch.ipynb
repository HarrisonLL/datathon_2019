{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import re\n",
    "import urllib\n",
    "import html2text\n",
    "import nltk\n",
    "\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "syf_page_url = \"https://www.marketwatch.com/investing/stock/syf\"\n",
    "uClient = uReq(syf_page_url)\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    "header_tags = page_soup.findAll(\"h3\", class_ = \"article__headline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string_tags = str(headers_tag)\n",
    "# string_test = \"2017\"\n",
    "# if string_test in string_tags : print(\"true\")\n",
    "# else: print(\"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for-better-interest-on-your-savings-look-to-these-banks-2018-11-14\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "header_string_list = []\n",
    "for header_tag in header_tags :\n",
    "    header_string = str(header_tag)\n",
    "    front_idx = header_string.find(\"href=\") + 5\n",
    "    new_header_string = header_string[front_idx:]\n",
    "    \n",
    "    begin_idx = 0\n",
    "    stop_idx = 0\n",
    "    slash_count = 0\n",
    "    \n",
    "    for i in range(len(new_header_string)) :\n",
    "        if new_header_string[i] == \"/\" :\n",
    "            slash_count += 1\n",
    "            if slash_count == 4:\n",
    "                begin_idx = i + 1\n",
    "        if new_header_string[i] == \">\" :\n",
    "            stop_idx = i\n",
    "            break\n",
    "\n",
    "    new_header_string2 =  new_header_string[begin_idx:stop_idx]\n",
    "    header_string_list.append(new_header_string2)\n",
    "print(header_string_list[10]) \n",
    "\n",
    "\n",
    "titles = []\n",
    "dates = []\n",
    "titles_dates = {}\n",
    "for header_string in header_string_list :\n",
    "    year = \"\"\n",
    "    month = \"\"\n",
    "    day = \"\"\n",
    "    end_idx = 0\n",
    "    find1 = header_string.find(\"2019\")\n",
    "    find2 = header_string.find(\"2018\")\n",
    "    find3 = header_string.find(\"2017\")\n",
    "    if find1 == -1 and find2 == -1 and find3 == -1:\n",
    "        continue\n",
    "    else :\n",
    "        if find1 != -1: \n",
    "            year = str(2019)\n",
    "            month = str(header_string[find1+5]) + str(header_string[find1+6]) \n",
    "            date =  str(header_string[find1+8]) + str(header_string[find1+9]) \n",
    "            end_idx = find1 - 2\n",
    "        elif find2 != -1: \n",
    "            year = str(2018)\n",
    "            month = str(header_string[find2+5]) + str(header_string[find2+6]) \n",
    "            date =  str(header_string[find2+8]) + str(header_string[find2+9]) \n",
    "            end_idx = find2 - 2\n",
    "        elif find3 != -1: \n",
    "            year = str(2017)\n",
    "            month = str(header_string[find3+5]) + str(header_string[find3+6]) \n",
    "            date =  str(header_string[find3+8]) + str(header_string[find3+9])\n",
    "            end_idx = find3 - 1\n",
    "        sp_date = month + \"/\" + date + \"/\" + year\n",
    "        dates.append(sp_date)\n",
    "        sp_title = header_string[:end_idx].replace(\"-\", \" \")\n",
    "        titles.append(sp_title)\n",
    "        titles_dates[sp_title] = sp_date\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dow-earnings-reporters-stocks-would-boost-dows-price-by-11-points-2019-01-29\"\n"
     ]
    }
   ],
   "source": [
    "##mmm\n",
    "syf_page_url = \"https://www.marketwatch.com/investing/stock/mmm\"\n",
    "uClient = uReq(syf_page_url)\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    "header_tags = page_soup.findAll(\"h3\", class_ = \"article__headline\")\n",
    "\n",
    "\n",
    "header_string_list = []\n",
    "for header_tag in header_tags :\n",
    "    header_string = str(header_tag)\n",
    "    front_idx = header_string.find(\"href=\") + 5\n",
    "    new_header_string = header_string[front_idx:]\n",
    "    \n",
    "    begin_idx = 0\n",
    "    stop_idx = 0\n",
    "    slash_count = 0\n",
    "    \n",
    "    for i in range(len(new_header_string)) :\n",
    "        if new_header_string[i] == \"/\" :\n",
    "            slash_count += 1\n",
    "            if slash_count == 4:\n",
    "                begin_idx = i + 1\n",
    "        if new_header_string[i] == \">\" :\n",
    "            stop_idx = i\n",
    "            break\n",
    "\n",
    "    new_header_string2 =  new_header_string[begin_idx:stop_idx]\n",
    "    header_string_list.append(new_header_string2)\n",
    "print(header_string_list[10]) \n",
    "\n",
    "\n",
    "titles1 = []\n",
    "dates1 = []\n",
    "for header_string in header_string_list :\n",
    "    year = \"\"\n",
    "    month = \"\"\n",
    "    day = \"\"\n",
    "    end_idx = 0\n",
    "    find1 = header_string.find(\"2019\")\n",
    "    find2 = header_string.find(\"2018\")\n",
    "    find3 = header_string.find(\"2017\")\n",
    "    if find1 == -1 and find2 == -1 and find3 == -1:\n",
    "        continue\n",
    "    else :\n",
    "        if find1 != -1: \n",
    "            year = str(2019)\n",
    "            month = str(header_string[find1+5]) + str(header_string[find1+6]) \n",
    "            date =  str(header_string[find1+8]) + str(header_string[find1+9]) \n",
    "            end_idx = find1 - 2\n",
    "        elif find2 != -1: \n",
    "            year = str(2018)\n",
    "            month = str(header_string[find2+5]) + str(header_string[find2+6]) \n",
    "            date =  str(header_string[find2+8]) + str(header_string[find2+9]) \n",
    "            end_idx = find2 - 2\n",
    "        elif find3 != -1: \n",
    "            year = str(2017)\n",
    "            month = str(header_string[find3+5]) + str(header_string[find3+6]) \n",
    "            date =  str(header_string[find3+8]) + str(header_string[find3+9])\n",
    "            end_idx = find3 - 1\n",
    "        sp_date = month + \"/\" + date + \"/\" + year\n",
    "        dates1.append(sp_date)\n",
    "        sp_title = header_string[:end_idx].replace(\"-\", \" \")\n",
    "        titles1.append(sp_title)\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class=\"article__headline\"\n"
     ]
    }
   ],
   "source": [
    "##hon\n",
    "\n",
    "syf_page_url = \"https://www.marketwatch.com/investing/stock/hon\"\n",
    "uClient = uReq(syf_page_url)\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    "header_tags = page_soup.findAll(\"h3\", class_ = \"article__headline\")\n",
    "\n",
    "\n",
    "header_string_list = []\n",
    "for header_tag in header_tags :\n",
    "    header_string = str(header_tag)\n",
    "    front_idx = header_string.find(\"href=\") + 5\n",
    "    new_header_string = header_string[front_idx:]\n",
    "    \n",
    "    begin_idx = 0\n",
    "    stop_idx = 0\n",
    "    slash_count = 0\n",
    "    \n",
    "    for i in range(len(new_header_string)) :\n",
    "        if new_header_string[i] == \"/\" :\n",
    "            slash_count += 1\n",
    "            if slash_count == 4:\n",
    "                begin_idx = i + 1\n",
    "        if new_header_string[i] == \">\" :\n",
    "            stop_idx = i\n",
    "            break\n",
    "\n",
    "    new_header_string2 =  new_header_string[begin_idx:stop_idx]\n",
    "    header_string_list.append(new_header_string2)\n",
    "print(header_string_list[10]) \n",
    "\n",
    "\n",
    "titles2 = []\n",
    "dates2 = []\n",
    "titles_dates = {}\n",
    "for header_string in header_string_list :\n",
    "    year = \"\"\n",
    "    month = \"\"\n",
    "    day = \"\"\n",
    "    end_idx = 0\n",
    "    find1 = header_string.find(\"2019\")\n",
    "    find2 = header_string.find(\"2018\")\n",
    "    find3 = header_string.find(\"2017\")\n",
    "    if find1 == -1 and find2 == -1 and find3 == -1:\n",
    "        continue\n",
    "    else :\n",
    "        if find1 != -1: \n",
    "            year = str(2019)\n",
    "            month = str(header_string[find1+5]) + str(header_string[find1+6]) \n",
    "            date =  str(header_string[find1+8]) + str(header_string[find1+9]) \n",
    "            end_idx = find1 - 2\n",
    "        elif find2 != -1: \n",
    "            year = str(2018)\n",
    "            month = str(header_string[find2+5]) + str(header_string[find2+6]) \n",
    "            date =  str(header_string[find2+8]) + str(header_string[find2+9]) \n",
    "            end_idx = find2 - 2\n",
    "        elif find3 != -1: \n",
    "            year = str(2017)\n",
    "            month = str(header_string[find3+5]) + str(header_string[find3+6]) \n",
    "            date =  str(header_string[find3+8]) + str(header_string[find3+9])\n",
    "            end_idx = find3 - 1\n",
    "        sp_date = month + \"/\" + date + \"/\" + year\n",
    "        dates2.append(sp_date)\n",
    "        sp_title = header_string[:end_idx].replace(\"-\", \" \")\n",
    "        titles2.append(sp_title)\n",
    "        titles_dates[sp_title] = sp_date\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4227653-portfolio-update-stocks-getting-slammed-dividends-shine-bright?source=marketwatch\" rel=\"nofollow\" target=\"_blank\"\n"
     ]
    }
   ],
   "source": [
    "##bayzf\n",
    "\n",
    "syf_page_url = \"https://www.marketwatch.com/investing/stock/bayzf\"\n",
    "uClient = uReq(syf_page_url)\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    "header_tags = page_soup.findAll(\"h3\", class_ = \"article__headline\")\n",
    "\n",
    "\n",
    "header_string_list = []\n",
    "for header_tag in header_tags :\n",
    "    header_string = str(header_tag)\n",
    "    front_idx = header_string.find(\"href=\") + 5\n",
    "    new_header_string = header_string[front_idx:]\n",
    "    \n",
    "    begin_idx = 0\n",
    "    stop_idx = 0\n",
    "    slash_count = 0\n",
    "    \n",
    "    for i in range(len(new_header_string)) :\n",
    "        if new_header_string[i] == \"/\" :\n",
    "            slash_count += 1\n",
    "            if slash_count == 4:\n",
    "                begin_idx = i + 1\n",
    "        if new_header_string[i] == \">\" :\n",
    "            stop_idx = i\n",
    "            break\n",
    "\n",
    "    new_header_string2 =  new_header_string[begin_idx:stop_idx]\n",
    "    header_string_list.append(new_header_string2)\n",
    "print(header_string_list[10]) \n",
    "\n",
    "\n",
    "titles3 = []\n",
    "dates3 = []\n",
    "titles_dates = {}\n",
    "for header_string in header_string_list :\n",
    "    year = \"\"\n",
    "    month = \"\"\n",
    "    day = \"\"\n",
    "    end_idx = 0\n",
    "    find1 = header_string.find(\"2019\")\n",
    "    find2 = header_string.find(\"2018\")\n",
    "    find3 = header_string.find(\"2017\")\n",
    "    if find1 == -1 and find2 == -1 and find3 == -1:\n",
    "        continue\n",
    "    else :\n",
    "        if find1 != -1: \n",
    "            year = str(2019)\n",
    "            month = str(header_string[find1+5]) + str(header_string[find1+6]) \n",
    "            date =  str(header_string[find1+8]) + str(header_string[find1+9]) \n",
    "            end_idx = find1 - 2\n",
    "        elif find2 != -1: \n",
    "            year = str(2018)\n",
    "            month = str(header_string[find2+5]) + str(header_string[find2+6]) \n",
    "            date =  str(header_string[find2+8]) + str(header_string[find2+9]) \n",
    "            end_idx = find2 - 2\n",
    "        elif find3 != -1: \n",
    "            year = str(2017)\n",
    "            month = str(header_string[find3+5]) + str(header_string[find3+6]) \n",
    "            date =  str(header_string[find3+8]) + str(header_string[find3+9])\n",
    "            end_idx = find3 - 1\n",
    "        sp_date = month + \"/\" + date + \"/\" + year\n",
    "        dates3.append(sp_date)\n",
    "        sp_title = header_string[:end_idx].replace(\"-\", \" \")\n",
    "        titles3.append(sp_title)\n",
    "        titles_dates[sp_title] = sp_date\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRITE TO FILE\n",
    "storage = {'Date' : \"\", 'CompanyName' : \"\", 'Text' : \"\"}\n",
    "\n",
    "\n",
    "for i in range(len(titles)) :\n",
    "    storage['Date'] = dates[i]\n",
    "    storage['CompanyName'] = \"SYF\"\n",
    "    storage['Text'] = titles[i]\n",
    "    with open('hottest_words.json', 'a') as outfile:  \n",
    "        json.dump(storage, outfile)\n",
    "        outfile.write('\\n')\n",
    "        outfile.close()\n",
    "\n",
    "for i in range(len(titles1)) :\n",
    "    storage['Date'] = dates1[i]\n",
    "    storage['CompanyName'] = \"MMM\"\n",
    "    storage['Text'] = titles1[i]\n",
    "    with open('hottest_words.json', 'a') as outfile:  \n",
    "        json.dump(storage, outfile)\n",
    "        outfile.write('\\n')\n",
    "        outfile.close()\n",
    "for i in range(len(titles2)) :\n",
    "    storage['Date'] = dates2[i]\n",
    "    storage['CompanyName'] = \"HON\"\n",
    "    storage['Text'] = titles2[i]\n",
    "    with open('hottest_words.json', 'a') as outfile:  \n",
    "        json.dump(storage, outfile)\n",
    "        outfile.write('\\n')\n",
    "        outfile.close()\n",
    "for i in range(len(titles3)) :\n",
    "    storage['Date'] = dates3[i]\n",
    "    storage['CompanyName'] = \"BAYZF\"\n",
    "    storage['Text'] = titles3[i]\n",
    "    with open('hottest_words.json', 'a') as outfile:  \n",
    "        json.dump(storage, outfile)\n",
    "        outfile.write('\\n')\n",
    "        outfile.close()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'so/rc/2018',\n",
       " 'CompanyName': 'BAYZF',\n",
       " 'Text': '4218606 u s dividend stocks discount octobe'}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
